{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple CSVs and JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_loader():\n",
    "    #Creating list of filenames\n",
    "    csv_files = glob('*.csv')\n",
    "    json_files = glob('*.json')\n",
    "\n",
    "    #Loading files into variables\n",
    "    df_list = list(map(lambda z: pd.read_csv(z,index_col='video_id'),\n",
    "                                                                 csv_files))\n",
    "    britain_js, germany_js, canada_js, france_js, usa_js = list(map(lambda a: json.load(open(a,'r')), \n",
    "                                                                                json_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    " \n",
    "def mat_loader():    \n",
    "    mnist_path = \"./mnist-original.mat\"\n",
    "    mnist_raw = loadmat(mnist_path)\n",
    "    mnist = {\n",
    "        \"data\": mnist_raw[\"data\"].T,\n",
    "        \"target\": mnist_raw[\"label\"][0],\n",
    "        \"COL_NAMES\": [\"label\", \"data\"],\n",
    "        \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Checker for columns in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_checker(data):\n",
    "    column_list = data.columns\n",
    "    Null_dict = {}   \n",
    "    for column in column_list:\n",
    "        Null_value_count = data[data[column].isnull() == True].count()[1]\n",
    "        Null_dict[column] = Null_value_count\n",
    "    \n",
    "    print(Null_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "\n",
    "    # Number of data points: n\n",
    "    n = len(data)     \n",
    "\n",
    "    # x-data for the ECDF: x\n",
    "    x = np.sort(data)\n",
    "\n",
    "    # y-data for the ECDF: y\n",
    "    y = np.arange(1, n+1) / n\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECDF with Percentiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ECDF\n",
    "_ = plt.plot(x_vers, y_vers, '.')\n",
    "plt.margins(0.02)\n",
    "_ = plt.xlabel('petal length (cm)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "\n",
    "# Overlay percentiles as red diamonds.\n",
    "_ = plt.plot(ptiles_vers, percentiles/100, marker='D', color='red',\n",
    "         linestyle='none')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Bernoulli Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_bernoulli_trials(n, p):\n",
    "    \"\"\"Perform n Bernoulli trials with success probability p\n",
    "    and return number of successes.\"\"\"\n",
    "    # Initialize number of successes: n_success\n",
    "    n_success = 0\n",
    "\n",
    "\n",
    "    # Perform trials\n",
    "    for i in range(n):\n",
    "        # Choose random number between zero and one: random_number\n",
    "        random_number = np.random.random()\n",
    "\n",
    "        # If less than p, it's a success so add one to n_success\n",
    "        if random_number<p:\n",
    "            n_success+=1\n",
    "\n",
    "    return n_success\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Bootstrap Samples and plotting them alongside original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # Generate bootstrap sample: bs_sample\n",
    "    bs_sample = np.random.choice(rainfall, size=len(rainfall))\n",
    "\n",
    "    # Compute and plot ECDF from bootstrap sample\n",
    "    x, y = ecdf(bs_sample)\n",
    "    _ = plt.plot(x, y, marker='.', linestyle='none',\n",
    "                 color='gray', alpha=0.1)\n",
    "\n",
    "# Compute and plot ECDF from original data\n",
    "x, y = ecdf(rainfall)\n",
    "_ = plt.plot(x, y, marker='.')\n",
    "\n",
    "# Make margins and label axes\n",
    "plt.margins(0.02)\n",
    "_ = plt.xlabel('yearly rainfall (mm)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Bootstrap replicates with specified function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_replicate_1d(data, func):\n",
    "    return func(np.random.choice(data, size=len(data)))\n",
    "\n",
    "def draw_bs_reps(data, func, size=1):\n",
    "    \"\"\"Draw bootstrap replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: bs_replicates\n",
    "    bs_replicates = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bootstrap_replicate1d(data, func)\n",
    "\n",
    "    return bs_replicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Pair Bootstrap Replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bs_pairs_linreg(x, y, size=1):\n",
    "    \"\"\"Perform pairs bootstrap for linear regression.\"\"\"\n",
    "\n",
    "    # Set up array of indices to sample from: inds\n",
    "    inds = np.arange(len(x))\n",
    "\n",
    "    # Initialize replicates: bs_slope_reps, bs_intercept_reps\n",
    "    bs_slope_reps = np.empty(size)\n",
    "    bs_intercept_reps = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_inds = np.random.choice(inds, size=len(inds))\n",
    "        bs_x, bs_y = x[bs_inds], y[bs_inds]\n",
    "        bs_slope_reps[i], bs_intercept_reps[i] = np.polyfit(bs_x,bs_y                                                             ,deg=1)\n",
    "\n",
    "    return bs_slope_reps, bs_intercept_reps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Linear Regression on Bootstrap Replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bs_pairs_linreg(x, y, size=1):\n",
    "    \"\"\"Perform pairs bootstrap for linear regression.\"\"\"\n",
    "\n",
    "    # Set up array of indices to sample from: inds\n",
    "    inds = np.arange(len(x))\n",
    "\n",
    "    # Initialize replicates: bs_slope_reps, bs_intercept_reps\n",
    "    bs_slope_reps = np.empty(size)\n",
    "    bs_intercept_reps = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_inds = np.random.choice(inds, size=len(inds))\n",
    "        bs_x, bs_y = x[bs_inds], y[bs_inds]\n",
    "        bs_slope_reps[i], bs_intercept_reps[i] = np.polyfit(bs_x,bs_y                                                             ,deg=1)\n",
    "\n",
    "    return bs_slope_reps, bs_intercept_reps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Plot using Bootstrap Replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array of x-values for bootstrap lines: x\n",
    "x = np.array([0,100])\n",
    "\n",
    "# Plot the bootstrap lines\n",
    "for i in range(100):\n",
    "    _ = plt.plot(x, bs_slope_reps[i]*x + bs_intercept_reps[i],\n",
    "                 linewidth=0.5, alpha=0.2, color='red')\n",
    "\n",
    "# Plot the data\n",
    "_ = plt.plot(illiteracy, fertility, linestyle='none', marker='.')\n",
    "\n",
    "# Label axes, set the margins, and show the plot\n",
    "_ = plt.xlabel('illiteracy')\n",
    "_ = plt.ylabel('fertility')\n",
    "plt.margins(0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Permutation Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
    "\n",
    "    # Concatenate the data sets: data\n",
    "    data = np.concatenate((data1, data2))\n",
    "\n",
    "    # Permute the concatenated array: permuted_data\n",
    "    permuted_data = np.random.permutation(data)\n",
    "\n",
    "    # Split the permuted array into two: perm_sample_1, perm_sample_2\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "\n",
    "    return perm_sample_1, perm_sample_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Permutation Replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_perm_reps(data_1, data_2, func, size=1):\n",
    "    \"\"\"Generate multiple permutation replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: perm_replicates\n",
    "    perm_replicates = np.empty(size)\n",
    "\n",
    "    for i in range(size):\n",
    "        # Generate permutation sample\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
    "\n",
    "        # Compute the test statistic\n",
    "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
    "\n",
    "    return perm_replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_of_means(data_1, data_2):\n",
    "    \"\"\"Difference in means of two arrays.\"\"\"\n",
    "\n",
    "    # The difference of means of data_1, data_2: diff\n",
    "    diff = np.mean(data_1) - np.mean(data_2)\n",
    "\n",
    "    return diff\n",
    "\n",
    "# Compute difference of mean impact force from experiment: empirical_diff_means\n",
    "empirical_diff_means = diff_of_means(force_a, force_b)\n",
    "\n",
    "# Draw 10,000 permutation replicates: perm_replicates\n",
    "perm_replicates = draw_perm_reps(force_a, force_b,\n",
    "                                 diff_of_means, size=10000)\n",
    "\n",
    "# Compute p-value: p\n",
    "p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)\n",
    "\n",
    "# Print the result\n",
    "print('p-value =', p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting data using new mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_force_b = force_b - old_mean + new_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_maker():\n",
    "    py3_users = df.iloc[:,42][df.iloc[:,42]=='Python 3'].count()\n",
    "    py2_users = df.iloc[:,42][df.iloc[:,42]=='Python 2'].count()\n",
    "\n",
    "    plt.pie(x=[py3_users,py2_users], labels=['Python 3', 'Python 2'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizer(x, y, plot_type, title, xlabel, ylabel, rotation=False, rotation_value=60, figsize=(15,8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if plot_type == \"bar\":  \n",
    "        sns.barplot(x=x, y=y)\n",
    "    elif plot_type == \"count\":  \n",
    "        sns.countplot(x)\n",
    "    elif plot_type == \"reg\":  \n",
    "        sns.regplot(x=x,y=y)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    \n",
    "    if rotation == True:\n",
    "        plt.xticks(rotation=rotation_value)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def three_dplot():\n",
    "    subplot3d = plt.subplot(111, projection='3d')\n",
    "    x_coords, y_coords, z_coords = zip(a,b)\n",
    "    subplot3d.scatter(x_coords, y_coords, z_coords)\n",
    "    subplot3d.set_zlim3d([0, 9])\n",
    "    plt.show()\n",
    "\n",
    "def plot_vectors3d(ax, vectors3d, z0, **options):\n",
    "    for v in vectors3d:\n",
    "        x, y, z = v\n",
    "        ax.plot([x,x], [y,y], [z0, z], color=\"gray\", linestyle='dotted', marker=\".\")\n",
    "    x_coords, y_coords, z_coords = zip(*vectors3d)\n",
    "    ax.scatter(x_coords, y_coords, z_coords, **options)\n",
    "\n",
    "\"\"\"\n",
    "subplot3d = plt.subplot(111, projection='3d')\n",
    "subplot3d.set_zlim([0, 9])\n",
    "plot_vectors3d(subplot3d, [a,b], 0, color=(\"r\",\"b\"))\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def stratified_sampler(data, column, n_splits=1, test_size=0.2, random_state=42):\n",
    "    split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    for train_index, test_index in split.split(data, data[column]):\n",
    "        strat_test_set = data.loc[test_index]\n",
    "        strat_train_set = data.loc[train_index]\n",
    "    return (strat_train_set, strat_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "def stratifed_k_fold():\n",
    "    for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "        clone_clf = clone(sgd)\n",
    "        X_train_folds = X_train[train_index]\n",
    "        y_train_folds = (y_train_5[train_index])\n",
    "        X_test_fold = X_train[test_index]\n",
    "        y_test_fold = (y_train_5[test_index])\n",
    "        clone_clf.fit(X_train_folds, y_train_folds)\n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        n_correct = sum(y_pred == y_test_fold)\n",
    "        print(n_correct / len(y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Label Encoder for Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class dual_encoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self):\n",
    "        return self\n",
    "    def transform(self):\n",
    "        pass\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.encoder_cont = LabelEncoder()\n",
    "        cont_encoded = self.encoder_cont.fit_transform(X['cont_rating'])\n",
    "        \n",
    "        self.encoder_prime_genre = LabelEncoder()\n",
    "        genre_encoded = self.encoder_prime_genre.fit_transform(X['prime_genre'])\n",
    "        \n",
    "        X[\"cont_encoded\"] = cont_encoded\n",
    "        X[\"genre_encoded\"] = genre_encoded\n",
    "        \n",
    "        return X.drop([\"cont_rating\", \"prime_genre\"], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame selector for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Polynomial feature for PolyRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def poly():\n",
    "    poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_poly, y)\n",
    "    lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines and FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_and_featureunion():\n",
    "    from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    category_attributes = [\"cont_rating\",\"prime_genre\"]\n",
    "    numerical_attributes = store_data.drop([\"cont_rating\",\"prime_genre\"], axis=1).columns\n",
    "\n",
    "    numline = Pipeline([(\"dataframe\", DataFrameSelector(numerical_attributes)),\n",
    "                        (\"dropper\", dropper()),\n",
    "                        (\"version-trimmer\", version_trimmer())])\n",
    "\n",
    "    encoder = dual_encoder()\n",
    "\n",
    "    catline = Pipeline([(\"dataframe\", DataFrameSelector(category_attributes)),\n",
    "                        (\"cat-encoder\", encoder)])\n",
    "\n",
    "    full_pipeline = FeatureUnion(transformer_list=[(\"num_pipeline\", numline),\n",
    "                                                   (\"cat_pipeline\", catline)])\n",
    "\n",
    "    store_data_prepared = full_pipeline.fit_transform(store_data)\n",
    "\n",
    "    print(store_data_prepared)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping or beautiful free lunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def early_stopper():\n",
    "    sgd_reg = SGDRegressor(n_iter=1, warm_start=True, penalty=None,\n",
    "    learning_rate=\"constant\", eta0=0.0005)\n",
    "    minimum_val_error = float(\"inf\")\n",
    "    best_epoch = None\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        sgd_reg.fit(X_train_poly_scaled, y_train) # continues where it left off\n",
    "        y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
    "        val_error = mean_squared_error(y_val_predict, y_val)\n",
    "        if val_error < minimum_val_error:\n",
    "            minimum_val_error = val_error\n",
    "            best_epoch = epoch\n",
    "            best_model = clone(sgd_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Scoring ML model(Using Negative root mean squared error) made easy\n",
    "def model_scoring(model_name, model, X, y):\n",
    "    \n",
    "    #Cross Validation\n",
    "    scores = cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    \n",
    "    #Scores\n",
    "    rmse = np.sqrt(-scores)\n",
    "    mean = rmse.mean()\n",
    "    std = rmse.std()\n",
    "    print(model_name)\n",
    "    print()\n",
    "    print(\"RMSE: {}\".format(rmse))\n",
    "    print(\"MEAN: {}\".format(mean))\n",
    "    print(\"STD: {}\".format(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating training error and validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "        val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling ML models alongwith metrics and train-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickler(name, model, predictions, training_data, training_label=None, cross_val_score=None, **kwargs):\n",
    "    \n",
    "    #Making dicitonary\n",
    "    import numpy as np\n",
    "    pickle_dict = {}\n",
    "    pickle_name = name+\".pickle\"\n",
    "    pickle_dict[\"ML Model\"] = model\n",
    "    pickle_dict[\"Predictions\"] = np.array(predictions)\n",
    "    pickle_dict[\"Training Data\"] = np.array(training_data)\n",
    "    pickle_dict[\"Training Labels\"] = np.array(training_label)\n",
    "    for key, value in kwargs.items():\n",
    "        pickle_dict[key] = value\n",
    "    \n",
    "    #Pickling the dictionary\n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(pickle_dict, pickle_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
